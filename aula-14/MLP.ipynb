{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83f9cfe",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f98c0",
   "metadata": {},
   "source": [
    "### Definação da classe MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc19952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MLPClassifier:\n",
    "    def __init__(self, hidden_layers=[64, 32], activation='relu', learning_rate=0.01,\n",
    "                 epochs=100, patience=5, batch_size=32, optimizer='sgd', regularization='None',\n",
    "                 dropout_p=0.1, lambda_l2=0.001, random_state=None):\n",
    "\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation.lower()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer.lower()\n",
    "        self.regularization = regularization\n",
    "        self.dropout_p = dropout_p\n",
    "        self.lambda_l2 = lambda_l2\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.model = None\n",
    "        self.loss_history = {'train': [], 'val': []}\n",
    "        self.accuracy_history = {'train': [], 'val': []}\n",
    "        self.classes_ = None\n",
    "\n",
    "        # CPU apenas\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        print(\"Usando dispositivo: CPU\")\n",
    "        print(f\"Cuda habilitado? {torch.cuda.is_available()}\")\n",
    "\n",
    "        if random_state is not None:\n",
    "            torch.manual_seed(random_state)\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "    \n",
    "    def _build_model(self, input_dim, output_dim):\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for dim in self.hidden_layers:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "\n",
    "            if self.activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif self.activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            \n",
    "            if self.regularization == 'dropout':\n",
    "                layers.append(nn.Dropout(p=self.dropout_p))\n",
    "\n",
    "            prev_dim = dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "\n",
    "        return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        start = time.time()\n",
    "\n",
    "        # Tensores CPU\n",
    "        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n",
    "        y_train_tensor = torch.LongTensor(y_train).to(self.device)\n",
    "\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_val_tensor = torch.FloatTensor(X_val).to(self.device)\n",
    "            y_val_tensor = torch.LongTensor(y_val).to(self.device)\n",
    "            validation_data = (X_val_tensor, y_val_tensor)\n",
    "        else:\n",
    "            validation_data = None\n",
    "\n",
    "        # Inicializar modelo\n",
    "        input_dim = X_train.shape[1]\n",
    "        self.classes_ = torch.unique(y_train_tensor)\n",
    "        output_dim = len(self.classes_)\n",
    "\n",
    "        self.model = self._build_model(input_dim, output_dim)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss() if output_dim > 1 else nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Otimizador\n",
    "        if self.optimizer == 'sgd':\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer == 'adam':\n",
    "            if self.regularization == 'l2':\n",
    "                optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.lambda_l2)\n",
    "            else:\n",
    "                optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"O otimizador deve ser 'sgd' ou 'adam'.\")\n",
    "        \n",
    "        # Early stopping\n",
    "        best_loss = np.inf\n",
    "        patience_counter = 0\n",
    "        best_weights = None\n",
    "\n",
    "        # Loop de treinamento\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for i in range(0, len(X_train), self.batch_size):\n",
    "                batch_X = X_train_tensor[i:i+self.batch_size]\n",
    "                batch_y = y_train_tensor[i:i+self.batch_size]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "                total += batch_y.size(0)\n",
    "\n",
    "            # Métricas\n",
    "            train_loss = epoch_loss / (len(X_train) / self.batch_size)\n",
    "            train_acc = correct / total\n",
    "            self.loss_history['train'].append(train_loss)\n",
    "            self.accuracy_history['train'].append(train_acc)\n",
    "\n",
    "            # Validação\n",
    "            val_loss, val_acc = None, None\n",
    "            if validation_data is not None:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    Xv, yv = validation_data\n",
    "                    outputs = self.model(Xv)\n",
    "                    val_loss = criterion(outputs, yv).item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_acc = (predicted == yv).sum().item() / len(yv)\n",
    "\n",
    "                self.loss_history['val'].append(val_loss)\n",
    "                self.accuracy_history['val'].append(val_acc)\n",
    "\n",
    "                # Early stopping\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_weights = self.model.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= self.patience:\n",
    "                        print(f\"Early stopping na época {epoch+1}\")\n",
    "                        self.model.load_state_dict(best_weights)\n",
    "                        break\n",
    "\n",
    "            # Log\n",
    "            if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "                msg = f\"Época {epoch+1}/{self.epochs} - Loss Treino: {train_loss:.4f}, Acc: {train_acc*100:.2f}%\"\n",
    "                if val_loss is not None:\n",
    "                    msg += f\", Loss Val: {val_loss:.4f}, Acc Val: {val_acc*100:.2f}%\"\n",
    "                print(msg)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"Tempo total de treinamento: {end - start:.2f} segundos\")\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"O modelo não foi treinado ainda. Chame fit() primeiro.\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "            outputs = self.model(X_tensor)\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "        return predictions.cpu().numpy()\n",
    "\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy\n",
    "\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        ax1.plot(self.loss_history['train'], label='Treino')\n",
    "        if len(self.loss_history['val']):\n",
    "            ax1.plot(self.loss_history['val'], label='Validação')\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.set_xlabel('Época')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.plot(self.accuracy_history['train'], label='Treino')\n",
    "        if len(self.accuracy_history['val']):\n",
    "            ax2.plot(self.accuracy_history['val'], label='Validação')\n",
    "        ax2.set_title('Acurácia')\n",
    "        ax2.set_xlabel('Época')\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def plot_decision_boundary(self, X, y, step=0.02):\n",
    "        if X.shape[1] != 2:\n",
    "            print(\"A fronteira de decisão só pode ser plotada para dados 2D.\")\n",
    "            return\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "        y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                             np.arange(y_min, y_max, step))\n",
    "        grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "        predictions = self.predict(grid_points).reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, predictions, alpha=0.75)\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "        plt.title('Fronteira de Decisão')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa0fb6",
   "metadata": {},
   "source": [
    "### 1° Caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de Treinamento\n",
    "data = np.genfromtxt('C:/aprendizagem-de-maquina/datasets/train_dataset3.csv', delimiter=',', skip_header=1)\n",
    "X_train = data[:, :-1]  # Features\n",
    "y_train = data[:, -1]   # Labels\n",
    "y_train = (y_train + 1) // 2\n",
    "\n",
    "# Dataset de Teste\n",
    "data = np.genfromtxt('C:/aprendizagem-de-maquina/datasets/test_dataset3.csv', delimiter=',', skip_header=1)\n",
    "X_test = data[:, :-1]   # Features\n",
    "y_test = data[:, -1]    # Labels\n",
    "y_test = (y_test + 1) // 2\n",
    "\n",
    "# 1° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d708fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac883073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='tanh')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2183ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf75fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93417c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b06b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18° Caso\n",
    "mlp = MLPClassifier(optimizer='sgd',\n",
    "                    learning_rate=0.01,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d788b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: CPU\n",
      "Cuda habilitado? False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'sgd'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m mlp = MLPClassifier(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m                     learning_rate=\u001b[32m0.001\u001b[39m,\n\u001b[32m      4\u001b[39m                     hidden_layers=[\u001b[32m50\u001b[39m,\u001b[32m64\u001b[39m,\u001b[32m4\u001b[39m],\n\u001b[32m      5\u001b[39m                     activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Treinar o modelo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mmlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Avaliar no conjunto de teste\u001b[39;00m\n\u001b[32m     11\u001b[39m test_acc = mlp.evaluate(X_test, y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mMLPClassifier.fit\u001b[39m\u001b[34m(self, X_train, y_train, X_val, y_val)\u001b[39m\n\u001b[32m     91\u001b[39m         optimizer = optim.sgd(\u001b[38;5;28mself\u001b[39m.model.parameters(), lr=\u001b[38;5;28mself\u001b[39m.learning_rate, weight_decay=\u001b[38;5;28mself\u001b[39m.lambda_l2)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         optimizer = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43msgd\u001b[49m(\u001b[38;5;28mself\u001b[39m.model.parameters(), lr=\u001b[38;5;28mself\u001b[39m.learning_rate)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mO otimizador deve ser \u001b[39m\u001b[33m'\u001b[39m\u001b[33msgd\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ou \u001b[39m\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch.optim' has no attribute 'sgd'"
     ]
    }
   ],
   "source": [
    "# 19° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh')\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f31e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu',)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4,],\n",
    "                    activation='tanh',)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa62175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31776a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d91d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu',)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21798d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh',)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75588e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='dropout',\n",
    "                    dropout_p=0.1)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='relu',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36° Caso\n",
    "mlp = MLPClassifier(optimizer='adam',\n",
    "                    learning_rate=0.001,\n",
    "                    hidden_layers=[50,256,128,64,4],\n",
    "                    activation='tanh',\n",
    "                    regularization='l2',\n",
    "                    lambda_l2=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_acc = mlp.evaluate(X_test, y_test)\n",
    "print(f\"\\nAcurácia do Teste: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Plotar histórico de treinamento\n",
    "mlp.plot_training_history()\n",
    "\n",
    "# Plotar fronteira de decisão (apenas para dados 2D)\n",
    "mlp.plot_decision_boundary(X_train, y_train)\n",
    "mlp.predict(X_test)\n",
    "mlp.plot_decision_boundary(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
